#### Arnav Bhakta

#### What is one discovery you made about this process, and what is one lingering question you have? 

During this process, one thing I learned is how important it is to know what the dataset you are working with is. When working with data and different models in the past, to forecast outcomes, I’ve generally had a pretty good sense of what the dataset was, the relationship between features, and what they entail, primarily because I was directly involved in crafting the dataset and deciding which features to include. For this process, however, I was forced to take a step back and understand the relationship between features, by creating scatter plots, histograms, and getting statistics about the data, to get more insight into what the features presented. Moreover, I started this process with no idea about what the variables were, and it challenged my abilities to find more information about them, but also informed me of how significant it is to truly research your features, not only to decided if they are good predictors and if they should be kept in your dataset, but also to weigh the ethical background of the variables.

One lingering question I have is how to decide which variables to remove from the dataset when slicing it vertically. From my impression, I tried to remove variables that didn’t necessarily have a strong correlation with the median house value feature, and reduce multicollinearity in the set, by removing variables that were highly correlated with each other. However, I’m not sure if there are further issues I should consider when cleaning my dataset and removing certain features. I also had a question on how to know where to slice the data horizontally. From past experiences, I know that when splitting a dataset for training and testing, it should be roughly around a 70/30 split respectively, or more or less, based on the situation, but in the case of the lab, I had no idea about where I should start with slicing the dataset horizontally, and what factors I should consider when doing so.

#### If you worked on it, what did you discoveries did you make about the columns? What was your emotional response to those discoveries?

While working with the Boston Housing Dataset, I had initially used the built-in DESCR key that the dataset provided, to get a better understanding of what features were in the dataset. Upon doing so, I was surprised and worried to see that the “B” feature in the dataset represented a function related to the proportion of black people in the town, thinking that I had simply misread the predictor’s description. I was simply confused, to be honest, and tried to graph it against the median house value feature, but saw that there was very little correlation between them. I also tried to create a histogram for its values, but once again saw that there wasn’t necessarily a clear distribution, confusing me even more as to why it was included in the dataset. Funnily enough, societal and historical discriminations are topics that I am also discussing in History and English class, so with the disgust carried over from these classes, I attributed this feature to the umbrella of being a racially motivated idea. Outside of this feature, however, there were other features that made me question why they were included and made me sick to my stomach, such as the LSTAT feature (percent of the lower status of the population), the CRIM features (per capita crime rate by town), and the PTRATIO features (pupil-teacher ratio). All of these features are things that can’t necessarily be controlled, but I also know from previous discussions, that they create a false stigma about the community and affect the livelihoods of its people. This is unacceptable, and I was concerned to see that they were included as features of the dataset.

#### What do you believe is the author's argument about the "B" column, and what should we make of it?

I think the author’s argument about the “B” column is completely valid and something that I hadn’t thought of before reading the article. In essence, what I believe they are arguing, is that by transforming the column in the manner which they did, they made the data non-invertible, but also made it so that you can’t recover the original data, due to there being multiple x values for each y value, putting into question, the transformation and if it is purposefully transforming it to target certain racial groups. I am in complete agreement with the author, not only in the fact that the data for the feature being non-invertible raises a statistical issue, but that it also raises an ethical issue as well. For one, by transforming the data in the manner in which they did, they made it so that the original dataset was not recoverable, which is quite a faulty error, as, without it, it puts at risk the stationary and autoregressive characteristics of the data, which might mean that it might affect the actual model itself by being used as a predictor. It also means that the original data isn’t recoverable, which inhibits future studies and reviewers, who want to investigate more uses of the dataset. This point also highlights the ethical issue of the “B” column, which is that by not allowing us to see the original pre-transformation data, the researchers could be purposefully manipulating the data to have it such that they are discriminating against black people and specifically targetting them, by showing that they affect a house’s price. Another implication is that they could be trying to mask a mistake they made in crafting the dataset.

#### Does it mean that we should throw out and never use the Boston Housing Data Set, or does it have a use? Does it belong in a list of standard, so called "toy", data sets, for example in scikit-learn?

I don’t necessarily believe that we should completely stop using the Boston Housing Data Set, because similar to the iris dataset, we can use it as an educational opportunity, to teach people about ethical practices when using data. What I mean by this, is that if the Boston Housing Data Set was to remain exactly as it is, rather than using it to learn different machine learning algorithms, one could instead use it to learn what features aren’t necessarily acceptable and ethical to include in a dataset, and what ethical research entails. Additionally, it could help teach about historic events that might not be as well known, such as redlining, and raise the general public awareness surrounding it. Another option might be to remove certain features from the dataset and only include features that logically affect a house’s price, such as the average number of rooms, the full-values property-tax, etc. By doing so, the ability to use the dataset for practicing and learning different machine learning techniques would be preserved, as it honestly does provide a good base to learn more about how to use data, but it also removes the material that isn’t ethically correct and shouldn’t have been in the dataset in the first place. As for if it belongs in a list of standard “toy” datasets, I would say absolutely not. Even prior to this class, I had heard about the Boston Housing Data Set, and unknowingly used it, simply because of the richness of the data and how easy it is to access it. Thus, by including it in a list of standard datasets, it poses the risk of people unknowingly using it and thinking that the variables and features used in it, are standard in machine learning to achieve a higher accuracy and craft a better dataset, and having this ideology as they move forward to creating their own datasets to enhance their forecasts. In fact, I have heard reports of quant and fintech companies using very questionable datasets, and believe that by including “toy” sets such as the Bosting Housing Data Set, we are teaching people that using such features is okay as long as you are able to create a well-performing model.